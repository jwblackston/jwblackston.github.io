<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.4.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Walker Blackston">

  
  
  
    
  
  <meta name="description" content="from keras.datasets import reuters (train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)  Using TensorFlow backend. WARNING: Logging before flag parsing goes to stderr. W0714 18:24:28.310750 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead. W0714 18:24:28.311494 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead. W0714 18:24:28.312218 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead. W0714 18:24:28.312906 4580939200 deprecation_wrapper.">

  
  <link rel="alternate" hreflang="en-us" href="/post/reuters-headline-classification-model/">

  


  

  
  
  
  <meta name="theme-color" content="#4caf50">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.7dd90def5016c13c0f90c2d17b2f5d5c.css">

  

  
  
  

  

  

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="/post/reuters-headline-classification-model/">

  
  
  
  
    
    
  
  <meta property="twitter:card" content="summary">
  
  <meta property="og:site_name" content="Walker Blackston">
  <meta property="og:url" content="/post/reuters-headline-classification-model/">
  <meta property="og:title" content="Reuters Headline Classification Model | Walker Blackston">
  <meta property="og:description" content="from keras.datasets import reuters (train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)  Using TensorFlow backend. WARNING: Logging before flag parsing goes to stderr. W0714 18:24:28.310750 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead. W0714 18:24:28.311494 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead. W0714 18:24:28.312218 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead. W0714 18:24:28.312906 4580939200 deprecation_wrapper."><meta property="og:image" content="/img/icon-192.png">
  <meta property="twitter:image" content="/img/icon-192.png"><meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2019-08-16T11:44:06&#43;01:00">
  
  <meta property="article:modified_time" content="2019-08-16T11:44:06&#43;01:00">
  

  


  





  <title>Reuters Headline Classification Model | Walker Blackston</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Walker Blackston</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>About</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/cv.pdf"><span>CV</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        
        <li class="nav-item">
          <a class="nav-link js-dark-toggle" href="#"><i class="fas fa-moon" aria-hidden="true"></i></a>
        </li>
        

      </ul>

    </div>
  </div>
</nav>


  <article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Reuters Headline Classification Model</h1>

  

  
    



<meta content="2019-08-16 11:44:06 &#43;0100 BST" itemprop="datePublished">
<meta content="2019-08-16 11:44:06 &#43;0100 BST" itemprop="dateModified">

<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    <time>Aug 16, 2019</time>
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    9 min read
  </span>
  

  
  
  

  
  

  
    
<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=/post/reuters-headline-classification-model/&amp;text=Reuters%20Headline%20Classification%20Model" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=/post/reuters-headline-classification-model/&amp;t=Reuters%20Headline%20Classification%20Model" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook-f"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Reuters%20Headline%20Classification%20Model&amp;body=/post/reuters-headline-classification-model/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=/post/reuters-headline-classification-model/&amp;title=Reuters%20Headline%20Classification%20Model" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://web.whatsapp.com/send?text=Reuters%20Headline%20Classification%20Model%20/post/reuters-headline-classification-model/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=/post/reuters-headline-classification-model/&amp;title=Reuters%20Headline%20Classification%20Model" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>


  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<pre><code class="language-python">from keras.datasets import reuters
(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)
</code></pre>

<pre><code>Using TensorFlow backend.
WARNING: Logging before flag parsing goes to stderr.
W0714 18:24:28.310750 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

W0714 18:24:28.311494 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead.

W0714 18:24:28.312218 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead.

W0714 18:24:28.312906 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.CXX11_ABI_FLAG is deprecated. Please use tf.sysconfig.CXX11_ABI_FLAG instead.

W0714 18:24:28.313544 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow/__init__.py:98: The name tf.ConditionalAccumulator is deprecated. Please use tf.compat.v1.ConditionalAccumulator instead.
</code></pre>

<pre><code class="language-python">len(train_data)
</code></pre>

<pre><code>8982
</code></pre>

<pre><code class="language-python">len(test_data)
</code></pre>

<pre><code>2246
</code></pre>

<pre><code class="language-python">train_data[5]
</code></pre>

<pre><code>[1,
 4,
 37,
 38,
 309,
 213,
 349,
 1632,
 48,
 193,
 229,
 463,
 28,
 156,
 635,
 11,
 82,
 14,
 156,
 635,
 11,
 82,
 54,
 139,
 16,
 349,
 105,
 462,
 311,
 28,
 296,
 147,
 11,
 82,
 14,
 296,
 147,
 11,
 54,
 139,
 342,
 48,
 193,
 3234,
 361,
 122,
 23,
 1332,
 28,
 318,
 942,
 11,
 82,
 14,
 318,
 942,
 11,
 82,
 54,
 139,
 122,
 7,
 105,
 462,
 23,
 349,
 28,
 296,
 767,
 11,
 82,
 14,
 296,
 767,
 11,
 54,
 139,
 342,
 229,
 162,
 7,
 48,
 193,
 55,
 408,
 28,
 258,
 557,
 11,
 82,
 14,
 196,
 557,
 11,
 82,
 54,
 139,
 162,
 7,
 105,
 462,
 55,
 349,
 28,
 191,
 968,
 11,
 82,
 14,
 191,
 785,
 11,
 54,
 139,
 17,
 12]
</code></pre>

<pre><code class="language-python">import numpy as np

def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.
    return results

# Our vectorized training data
x_train = vectorize_sequences(train_data)
# Our vectorized test data
x_test = vectorize_sequences(test_data)
</code></pre>

<pre><code class="language-python">#one-hot encode our categorical variables, the keras way!
from keras.utils.np_utils import to_categorical

one_hot_train_labels = to_categorical(train_labels)
one_hot_test_labels = to_categorical(test_labels)
</code></pre>

<pre><code class="language-python">from keras import models
from keras import layers

model = models.Sequential()
model.add(layers.Dense(64, activation = 'relu', input_shape=(10000, )))
model.add(layers.Dense(64, activation = 'relu'))
model.add(layers.Dense(46, activation = 'softmax')) #46 due 46-dimensional output- this will output a probability function for all dimensional spaces added up to 1
</code></pre>

<pre><code class="language-python">model.compile(optimizer='rmsprop',
             loss = 'categorical_crossentropy', #due to the categorical nature of our target labels
             metrics = ['accuracy'])
</code></pre>

<pre><code>W0714 18:24:36.805853 4580939200 deprecation_wrapper.py:118] From /Users/walker/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.
</code></pre>

<pre><code class="language-python">x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = one_hot_train_labels[:1000]
partial_y_train = one_hot_train_labels[1000:]
</code></pre>

<pre><code class="language-python">history = model.fit(partial_x_train,
                   partial_y_train,
                    epochs = 20,
                    batch_size = 512,
                    validation_data = (x_val, y_val))
</code></pre>

<pre><code>W0714 18:24:39.409189 4580939200 deprecation.py:323] From /Users/walker/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1251: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where


Train on 7982 samples, validate on 1000 samples
Epoch 1/20
7982/7982 [==============================] - 1s 139us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120
Epoch 2/20
7982/7982 [==============================] - 1s 98us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060
Epoch 3/20
7982/7982 [==============================] - 1s 97us/step - loss: 1.0953 - acc: 0.7651 - val_loss: 1.1708 - val_acc: 0.7430
Epoch 4/20
7982/7982 [==============================] - 1s 98us/step - loss: 0.8697 - acc: 0.8165 - val_loss: 1.0793 - val_acc: 0.7590
Epoch 5/20
7982/7982 [==============================] - 1s 96us/step - loss: 0.7034 - acc: 0.8472 - val_loss: 0.9844 - val_acc: 0.7810
Epoch 6/20
7982/7982 [==============================] - 1s 98us/step - loss: 0.5667 - acc: 0.8802 - val_loss: 0.9411 - val_acc: 0.8040
Epoch 7/20
7982/7982 [==============================] - 1s 98us/step - loss: 0.4581 - acc: 0.9048 - val_loss: 0.9083 - val_acc: 0.8020
Epoch 8/20
7982/7982 [==============================] - 1s 96us/step - loss: 0.3695 - acc: 0.9231 - val_loss: 0.9363 - val_acc: 0.7890
Epoch 9/20
7982/7982 [==============================] - 1s 98us/step - loss: 0.3032 - acc: 0.9315 - val_loss: 0.8917 - val_acc: 0.8090
Epoch 10/20
7982/7982 [==============================] - 1s 97us/step - loss: 0.2537 - acc: 0.9414 - val_loss: 0.9071 - val_acc: 0.8110
Epoch 11/20
7982/7982 [==============================] - 1s 97us/step - loss: 0.2187 - acc: 0.9471 - val_loss: 0.9177 - val_acc: 0.8130
Epoch 12/20
7982/7982 [==============================] - 1s 98us/step - loss: 0.1873 - acc: 0.9508 - val_loss: 0.9027 - val_acc: 0.8130
Epoch 13/20
7982/7982 [==============================] - 1s 97us/step - loss: 0.1703 - acc: 0.9521 - val_loss: 0.9323 - val_acc: 0.8110
Epoch 14/20
7982/7982 [==============================] - 1s 98us/step - loss: 0.1536 - acc: 0.9554 - val_loss: 0.9689 - val_acc: 0.8050
Epoch 15/20
7982/7982 [==============================] - 1s 98us/step - loss: 0.1390 - acc: 0.9560 - val_loss: 0.9686 - val_acc: 0.8150
Epoch 16/20
7982/7982 [==============================] - 1s 99us/step - loss: 0.1313 - acc: 0.9560 - val_loss: 1.0220 - val_acc: 0.8060
Epoch 17/20
7982/7982 [==============================] - 1s 99us/step - loss: 0.1217 - acc: 0.9579 - val_loss: 1.0254 - val_acc: 0.7970
Epoch 18/20
7982/7982 [==============================] - 1s 97us/step - loss: 0.1198 - acc: 0.9582 - val_loss: 1.0430 - val_acc: 0.8060
Epoch 19/20
7982/7982 [==============================] - 1s 96us/step - loss: 0.1138 - acc: 0.9597 - val_loss: 1.0955 - val_acc: 0.7970
Epoch 20/20
7982/7982 [==============================] - 1s 97us/step - loss: 0.1111 - acc: 0.9593 - val_loss: 1.0674 - val_acc: 0.8020
</code></pre>

<pre><code class="language-python">#viz the accuracy and loss across 20 epochs:
import matplotlib.pyplot as plt

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(loss) + 1)

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
</code></pre>

<pre><code>&lt;Figure size 640x480 with 1 Axes&gt;
</code></pre>

<pre><code class="language-python">plt.clf() # clear figure
acc = history.history['acc']
val_acc = history.history['val_acc']
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
</code></pre>

<p><img src="reuters-headline-classification-model_files/reuters-headline-classification-model_11_0.png" alt="png" /></p>

<pre><code class="language-python">#looks like at around 9 epochs there's an asymptote of both model accuracy and loss
#re-train a model with 9 epochs:
model = models.Sequential()
model.add(layers.Dense(64, activation = 'relu', input_shape=(10000, )))
model.add(layers.Dense(64, activation = 'relu'))
model.add(layers.Dense(46, activation = 'softmax'))

model.compile(optimizer = 'rmsprop',
             loss = 'categorical_crossentropy',
             metrics = ['accuracy'])

model.fit(partial_x_train,
partial_y_train,
epochs=9, #change to 9 epochs from 20
batch_size=512,
validation_data=(x_val, y_val))
results = model.evaluate(x_test, one_hot_test_labels)
</code></pre>

<pre><code>Train on 7982 samples, validate on 1000 samples
Epoch 1/9
7982/7982 [==============================] - 1s 124us/step - loss: 2.8046 - acc: 0.5038 - val_loss: 1.8434 - val_acc: 0.6300
Epoch 2/9
7982/7982 [==============================] - 1s 96us/step - loss: 1.5257 - acc: 0.6957 - val_loss: 1.3305 - val_acc: 0.7120
Epoch 3/9
7982/7982 [==============================] - 1s 95us/step - loss: 1.1115 - acc: 0.7710 - val_loss: 1.1392 - val_acc: 0.7470
Epoch 4/9
7982/7982 [==============================] - 1s 97us/step - loss: 0.8719 - acc: 0.8146 - val_loss: 1.0308 - val_acc: 0.7850
Epoch 5/9
7982/7982 [==============================] - 1s 97us/step - loss: 0.7032 - acc: 0.8475 - val_loss: 0.9681 - val_acc: 0.8020
Epoch 6/9
7982/7982 [==============================] - 1s 96us/step - loss: 0.5661 - acc: 0.8753 - val_loss: 0.9420 - val_acc: 0.7980
Epoch 7/9
7982/7982 [==============================] - 1s 95us/step - loss: 0.4567 - acc: 0.9074 - val_loss: 0.9235 - val_acc: 0.7960
Epoch 8/9
7982/7982 [==============================] - 1s 95us/step - loss: 0.3709 - acc: 0.9238 - val_loss: 0.9698 - val_acc: 0.7920
Epoch 9/9
7982/7982 [==============================] - 1s 95us/step - loss: 0.3020 - acc: 0.9361 - val_loss: 0.8983 - val_acc: 0.8150
2246/2246 [==============================] - 0s 61us/step
</code></pre>

<pre><code class="language-python">results
</code></pre>

<pre><code>[0.979011650076957, 0.7894033837403343]
</code></pre>

<pre><code class="language-python">#verify predictions on novel data
predictions = model.predict(x_test)
</code></pre>

<pre><code class="language-python">predictions[0].shape
</code></pre>

<pre><code>(46,)
</code></pre>

<pre><code class="language-python">np.sum(predictions[0])
</code></pre>

<pre><code>1.0000001
</code></pre>

<h1 id="experiment-with-different-network-layers-and-units">Experiment with different Network Layers and Units:</h1>

<pre><code class="language-python">model_128u = models.Sequential()

model_128u.add(layers.Dense(128, activation='relu', input_shape=(10000,)))
model_128u.add(layers.Dense(128, activation='relu'))
model_128u.add(layers.Dense(46, activation = 'softmax'))

model_128u.compile(optimizer='rmsprop',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

hist_128u = model_128u.fit(partial_x_train,
                        partial_y_train,
                        epochs=20,
                        batch_size = 512,
                        validation_data = (x_val, y_val))
</code></pre>

<pre><code>Train on 7982 samples, validate on 1000 samples
Epoch 1/20
7982/7982 [==============================] - 1s 144us/step - loss: 2.1379 - acc: 0.5540 - val_loss: 1.3870 - val_acc: 0.6880
Epoch 2/20
7982/7982 [==============================] - 1s 86us/step - loss: 1.0956 - acc: 0.7648 - val_loss: 1.0949 - val_acc: 0.7690
Epoch 3/20
7982/7982 [==============================] - 1s 117us/step - loss: 0.7737 - acc: 0.8322 - val_loss: 0.9575 - val_acc: 0.8150
Epoch 4/20
7982/7982 [==============================] - 1s 118us/step - loss: 0.5631 - acc: 0.8834 - val_loss: 0.9109 - val_acc: 0.8090
Epoch 5/20
7982/7982 [==============================] - 1s 118us/step - loss: 0.4036 - acc: 0.9158 - val_loss: 0.8710 - val_acc: 0.8150
Epoch 6/20
7982/7982 [==============================] - 1s 117us/step - loss: 0.3238 - acc: 0.9315 - val_loss: 0.8674 - val_acc: 0.8220
Epoch 7/20
7982/7982 [==============================] - 1s 117us/step - loss: 0.2422 - acc: 0.9458 - val_loss: 0.8880 - val_acc: 0.8220
Epoch 8/20
7982/7982 [==============================] - 1s 118us/step - loss: 0.2104 - acc: 0.9486 - val_loss: 0.9060 - val_acc: 0.8190
Epoch 9/20
7982/7982 [==============================] - 1s 112us/step - loss: 0.1774 - acc: 0.9518 - val_loss: 0.9197 - val_acc: 0.8100
Epoch 10/20
7982/7982 [==============================] - 1s 117us/step - loss: 0.1621 - acc: 0.9525 - val_loss: 0.9367 - val_acc: 0.8100
Epoch 11/20
7982/7982 [==============================] - 1s 115us/step - loss: 0.1456 - acc: 0.9555 - val_loss: 0.9720 - val_acc: 0.8130
Epoch 12/20
7982/7982 [==============================] - 1s 95us/step - loss: 0.1337 - acc: 0.9578 - val_loss: 1.0050 - val_acc: 0.7970
Epoch 13/20
7982/7982 [==============================] - 1s 118us/step - loss: 0.1357 - acc: 0.9557 - val_loss: 0.9884 - val_acc: 0.8150
Epoch 14/20
7982/7982 [==============================] - 1s 116us/step - loss: 0.1292 - acc: 0.9562 - val_loss: 1.0644 - val_acc: 0.7970
Epoch 15/20
7982/7982 [==============================] - 1s 112us/step - loss: 0.1193 - acc: 0.9573 - val_loss: 1.0271 - val_acc: 0.8030
Epoch 16/20
7982/7982 [==============================] - 1s 117us/step - loss: 0.1165 - acc: 0.9573 - val_loss: 1.0800 - val_acc: 0.7970
Epoch 17/20
7982/7982 [==============================] - 1s 118us/step - loss: 0.1181 - acc: 0.9569 - val_loss: 1.0277 - val_acc: 0.7950
Epoch 18/20
7982/7982 [==============================] - 1s 118us/step - loss: 0.1093 - acc: 0.9572 - val_loss: 1.1501 - val_acc: 0.7920
Epoch 19/20
7982/7982 [==============================] - 1s 117us/step - loss: 0.1085 - acc: 0.9573 - val_loss: 1.0522 - val_acc: 0.8040
Epoch 20/20
7982/7982 [==============================] - 1s 87us/step - loss: 0.1081 - acc: 0.9578 - val_loss: 1.0899 - val_acc: 0.7930
</code></pre>

<pre><code class="language-python">plt.clf() # clear figure
acc = hist_128u.history['acc']
val_acc = hist_128u.history['val_acc']
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
</code></pre>

<p><img src="reuters-headline-classification-model_files/reuters-headline-classification-model_19_0.png" alt="png" /></p>

<pre><code class="language-python">#looks like we see the peak of our asymptote at around 7 epochs:
model_128u = models.Sequential()

model_128u.add(layers.Dense(128, activation='relu', input_shape=(10000,)))
model_128u.add(layers.Dense(128, activation='relu'))
model_128u.add(layers.Dense(46, activation = 'softmax'))

model_128u.compile(optimizer='rmsprop',
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

hist_128u = model_128u.fit(partial_x_train,
                        partial_y_train,
                        epochs=7,
                        batch_size = 512,
                        validation_data = (x_val, y_val))

result_128u = model_128u.evaluate(x_test, one_hot_test_labels)
</code></pre>

<pre><code>Train on 7982 samples, validate on 1000 samples
Epoch 1/7
7982/7982 [==============================] - 1s 151us/step - loss: 2.1407 - acc: 0.5378 - val_loss: 1.3850 - val_acc: 0.6630
Epoch 2/7
7982/7982 [==============================] - 1s 110us/step - loss: 1.0999 - acc: 0.7590 - val_loss: 1.0990 - val_acc: 0.7700
Epoch 3/7
7982/7982 [==============================] - 1s 117us/step - loss: 0.7843 - acc: 0.8310 - val_loss: 0.9611 - val_acc: 0.7960
Epoch 4/7
7982/7982 [==============================] - 1s 117us/step - loss: 0.5626 - acc: 0.8771 - val_loss: 0.9129 - val_acc: 0.8140
Epoch 5/7
7982/7982 [==============================] - 1s 119us/step - loss: 0.4093 - acc: 0.9154 - val_loss: 0.8941 - val_acc: 0.8050
Epoch 6/7
7982/7982 [==============================] - 1s 104us/step - loss: 0.3111 - acc: 0.9332 - val_loss: 0.9658 - val_acc: 0.7890
Epoch 7/7
7982/7982 [==============================] - 1s 117us/step - loss: 0.2485 - acc: 0.9427 - val_loss: 0.9028 - val_acc: 0.8060
2246/2246 [==============================] - 0s 49us/step
</code></pre>

<pre><code class="language-python">result_128u
</code></pre>

<pre><code>[0.9940730629493801, 0.786286731967943]
</code></pre>

    </div>

    


    



    
      








  





  
  
  
    
  
  
  <div class="media author-card" itemscope itemtype="http://schema.org/Person">
    
      
      <img class="portrait mr-3" src="/authors/admin/avatar_hu949f3ebb3444a38c1d213c8ca6e9c58e_34303_250x250_fill_q90_lanczos_center.jpg" itemprop="image" alt="Avatar">
    

    <div class="media-body">
      <h5 class="card-title" itemprop="name"><a href="/">Walker Blackston</a></h5>
      <h6 class="card-subtitle">PhD Student in Epidemiology and Biostatistics</h6>
      <p class="card-text" itemprop="description">I am a first year PhD student in Epidemiology and Biostatistics at Tulane University. My research interests lie at the intersection of epidemiological methods, causal inference, nutrition, and cardiometabolic kidney diseases.</p>
      <ul class="network-icon" aria-hidden="true">
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="/#contact" >
              <i class="fas fa-envelope"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://twitter.com/BlackstonWalker" target="_blank" rel="noopener">
              <i class="fab fa-twitter"></i>
            </a>
          </li>
        
          
          
          
            
          
          
          
          
          
            
          
          <li>
            <a itemprop="sameAs" href="https://github.com/jwblackston" target="_blank" rel="noopener">
              <i class="fab fa-github"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>



      
      
    

    

    


  </div>
</article>

      

    
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
      

      
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.4e51017b38c7ebaadd7e25fc9503f88c.js"></script>

    






  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    &copy; Walker Blackston 2019 &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
